- name: Setup basic actions on computers at home
  hosts: all

  vars_files:
  - ~/osobiste/dane_aplikacji/remik/ansible_vault.yml

  become: yes
  become_user: root
  serial: "{{ serial_number|default(3) }}"

# 
# Generic tasks
#
  tasks:
   - name: Install required packages
     apt:
       name: vim,jq
       state: present
     tags:
      - update
      - kafka_1.1.1

#
# Binaries
#
# Binaries for 0.10.1
   - name: Download kafka_2.10-0.10.1.0.tgz
     get_url:
       url: https://archive.apache.org/dist/kafka/0.10.1.0/kafka_2.10-0.10.1.0.tgz
       dest: /opt/kafka_2.10-0.10.1.0.tgz
       checksum: md5:8d78aaa8eb3853cedfd17f1b76596987
     tags:
      - kafka_0.10.1_bin

   - name: Extract kafka_2.10-0.10.1.0.tgz into /opt
     unarchive:
       src: /opt/kafka_2.10-0.10.1.0.tgz
       dest: /opt
       remote_src: yes
       creates: /opt/kafka_2.10-0.10.1.0
     tags:
      - kafka_0.10.1_bin

   - name: Create a symbolic link /opt/kafka -> /opt/kafka_2.10-0.10.1.0
     ansible.builtin.file:
       src: /opt/kafka_2.10-0.10.1.0
       dest: /opt/kafka
       state: link
       force: yes
     tags:
      - kafka_0.10.1_bin_link
# /Binaries for 0.10.1


# Binaries for 1.0.0
   - name: Download kafka_2.11-1.0.0.tgz
     get_url:
       url: https://archive.apache.org/dist/kafka/1.0.0/kafka_2.11-1.0.0.tgz
       dest: /opt/kafka_2.11-1.0.0.tgz
       checksum: md5:b652611004a992cd71f13b1dfe304b55
     tags:
      - kafka_1.0.0_bin

   - name: Extract kafka_2.11-1.0.0.tgz into /opt
     unarchive:
       src: /opt/kafka_2.11-1.0.0.tgz
       dest: /opt
       remote_src: yes
       creates: /opt/kafka_2.11-1.0.0
     tags:
      - kafka_1.0.0_bin
# /Binaries for 1.0.0

# Binaries for 1.1.1
   - name: Download kafka_2.12-1.1.1.tgz
     get_url:
       url: https://archive.apache.org/dist/kafka/1.1.1/kafka_2.12-1.1.1.tgz
       dest: /opt/kafka_2.12-1.1.1.tgz
       checksum: md5:29c20027940c5c6f83fffd393df78f09
     tags:
      - kafka_1.1.1_bin

   - name: Extract kafka_2.12-1.1.1.tgz into /opt
     unarchive:
       src: /opt/kafka_2.12-1.1.1.tgz
       dest: /opt
       remote_src: yes
       creates: /opt/kafka_2.12-1.1.1
     tags:
      - kafka_1.1.1_bin

   - name: Create a symbolic link /opt/kafka -> /opt/kafka_2.12-1.1.1
     ansible.builtin.file:
       src: /opt/kafka_2.12-1.1.1
       dest: /opt/kafka
       state: link
       force: yes
     tags:
      - kafka_1.1.1_bin_link
# /Binaries for 1.1.1

# Binaries for 2.3.0
   - name: Download kafka_2.12-2.3.0.tgz
     get_url:
       url: https://archive.apache.org/dist/kafka/2.3.0/kafka_2.12-2.3.0.tgz
       dest: /opt/kafka_2.12-2.3.0.tgz
       checksum: md5:8f86fb2421f6392f72bd8d7e1cfe4bf6
     tags:
      - kafka_2.3.0_bin

   - name: Extract kafka_2.12-2.3.0.tgz into /opt
     unarchive:
       src: /opt/kafka_2.12-2.3.0.tgz
       dest: /opt
       remote_src: yes
       creates: /opt/kafka_2.12-2.3.0
     tags:
      - kafka_2.3.0_bin

   - name: Create a symbolic link /opt/kafka -> /opt/kafka_2.12-2.3.0
     ansible.builtin.file:
       src: /opt/kafka_2.12-2.3.0
       dest: /opt/kafka
       state: link
       force: yes
     tags:
      - kafka_2.3.0_bin_link
# /Binaries for 2.3.0

# Binaries for 2.5.1
   - name: Download kafka_2.12-2.5.1.tgz
     get_url:
       url: https://archive.apache.org/dist/kafka/2.5.1/kafka_2.12-2.5.1.tgz
       dest: /opt/kafka_2.12-2.5.1.tgz
       checksum: md5:b4262ee6b2e843cd25a4e92a355ced0c
     tags:
      - kafka_2.5.1_bin

   - name: Extract kafka_2.12-2.5.1.tgz into /opt
     unarchive:
       src: /opt/kafka_2.12-2.5.1.tgz
       dest: /opt
       remote_src: yes
       creates: /opt/kafka_2.12-2.5.1
     tags:
      - kafka_2.5.1_bin

   - name: Create a symbolic link /opt/kafka -> /opt/kafka_2.12-2.5.1
     ansible.builtin.file:
       src: /opt/kafka_2.12-2.5.1
       dest: /opt/kafka
       state: link
       force: yes
     tags:
      - kafka_2.5.1_bin_link
# /Binaries for 2.5.1

# Binaries for 2.6.3
   - name: Download kafka_2.12-2.6.3.tgz
     get_url:
       url: https://archive.apache.org/dist/kafka/2.6.3/kafka_2.12-2.6.3.tgz
       dest: /opt/kafka_2.12-2.6.3.tgz
       checksum: md5:3eb610e6918cab898450567b1f7c1f7f
     tags:
      - kafka_2.6.3_bin

   - name: Extract kafka_2.12-2.6.3.tgz into /opt
     unarchive:
       src: /opt/kafka_2.12-2.6.3.tgz
       dest: /opt
       remote_src: yes
       creates: /opt/kafka_2.12-2.6.3
     tags:
      - kafka_2.6.3_bin

   - name: Create a symbolic link /opt/kafka -> /opt/kafka_2.12-2.6.3
     ansible.builtin.file:
       src: /opt/kafka_2.12-2.6.3
       dest: /opt/kafka
       state: link
       force: yes
     tags:
      - kafka_2.6.3_bin_link
# /Binaries for 2.6.3

# Binaries for 3.3.1
   - name: Download kafka_2.12-3.3.1.tgz
     get_url:
       url: https://archive.apache.org/dist/kafka/3.3.1/kafka_2.12-3.3.1.tgz
       dest: /opt/kafka_2.12-3.3.1.tgz
       checksum: md5:6d1db3717969ead1483e38c430cfdff2
     tags:
      - kafka_3.3.1_bin

   - name: Extract kafka_2.12-3.3.1.tgz into /opt
     unarchive:
       src: /opt/kafka_2.12-3.3.1.tgz
       dest: /opt
       remote_src: yes
       creates: /opt/kafka_2.12-3.3.1
     tags:
      - kafka_3.3.1_bin

   - name: Create a symbolic link /opt/kafka -> /opt/kafka_2.12-3.3.1
     ansible.builtin.file:
       src: /opt/kafka_2.12-3.3.1
       dest: /opt/kafka
       state: link
       force: yes
     tags:
      - kafka_3.3.1_bin_link
# /Binaries for 2.6.3










# Generic section for binaries
   - name: Create log dir
     file:
       path: /opt/kafka/logs
       state: directory
     tags:
      - kafka_3.3.1_bin
      - kafka_2.6.3_bin
      - kafka_2.5.1_bin
      - kafka_2.3.0_bin
      - kafka_1.1.1_bin
      - kafka_1.0.0_bin
      - kafka_0.10.1_bin

# /Generic section for binaries

#
# Vanilla Configuration files
#

   - name: Creates /var/log/mirror_maker directory
     ansible.builtin.file:
       path: /etc/kafka
       state: directory
       mode: '0755'
     tags:
      - kafka_2.3.0_conf

   - name: Copy vanilla 2.3.0 conf to /etc/kafka
     ansible.builtin.copy:
       src: ~/scripto/ansible/templates/server.properties_2.3.0
       dest: /etc/kafka/server.properties
       backup: yes
     tags:
      - kafka_2.3.0_conf


#
# Configuration changes
#
   - name: Creates /opt/kafka-data directory
     ansible.builtin.file:
       path: /opt/kafka-data
       state: directory
       mode: '0755'
     tags:
      - kafka_conf  


   - name: Modify server.properties listeners=PLAINTEXT
     replace:
       path: /etc/kafka/server.properties
       regexp: '^#listeners=PLAINTEXT'
       replace: 'listeners=PLAINTEXT'
     tags:
      - kafka_conf

   - name: Modify server.properties log.dirs
     replace:
       path: /etc/kafka/server.properties
       regexp: '^log.dirs=/tmp/kafka-logs'
       replace: 'log.dirs=/opt/kafka-data'
     tags:
      - kafka_conf

   - name: Modify server.properties add couple non default parameters
     blockinfile:
       path: /etc/kafka/server.properties
       block: |
         delete.topic.enable=true
         num.partitions=8
         default.replication.factor=3
         log.retention.hours=168
         zookeeper.connection.timeout.ms=6000
         auto.create.topics.enable=false
         offsets.topic.replication.factor=3
         min.insync.replicas=2
     tags:
      - kafka_conf


   - name: Modify server.properties broker.id and use last ip octet
     replace:
       path: /etc/kafka/server.properties
       regexp: '^broker.id=0'
       replace: 'broker.id={{ ansible_eth0.ipv4.address.split(".")[-1] }}'
     tags:
      - kafka_conf

   - name: "Modify server.properties zookeeper.connect, host variable zookeeper_location needs to be set like eg. zookeeper_location: monitoring:2181/kafka_consumer4"
     replace:
       path: /etc/kafka/server.properties
       regexp: '^zookeeper.connect=localhost:2181'
       replace: 'zookeeper.connect={{ zookeeper_location }}'
     tags:
      - kafka_conf

   - name: "Modify /opt/kafka/config/log4j.properties to not add hour to previous log names"
     replace:
       path: /opt/kafka/config/log4j.properties
       regexp: 'yyyy-MM-dd-HH'
       replace: 'yyyy-MM-dd'
     tags:
      - kafka_log4j
      - kafka_conf



#
# Upgrade
#
   - name: Upgrade - set inter.broker.protocol.version and log.message.format.version to 2.3
     blockinfile:
       path: /etc/kafka/server.properties
       backup: yes
       marker: "# {mark} ANSIBLE MANAGED UPGRADE BLOCK"
       block: |
         inter.broker.protocol.version=2.3
         log.message.format.version=2.3
     register: kafka_config
     tags:
      - kafka_protocol_message_2_3

   - name: Upgrade - set inter.broker.protocol.version and log.message.format.version to 2.6
     blockinfile:
       path: /etc/kafka/server.properties
       backup: yes
       marker: "# {mark} ANSIBLE MANAGED UPGRADE BLOCK"
       block: |
         inter.broker.protocol.version=2.6
         log.message.format.version=2.6
     register: kafka_config
     tags:
      - kafka_protocol_message_2_6

   - name: Restart Kafka if some configuration has changed
     service:
       name: kafka.service
       state: restarted
       enabled: yes
       daemon_reload: yes
     when: kafka_config.changed
     tags:
      - kafka_protocol_message_2_3
      - kafka_protocol_message_2_6

   - name: Wait 10 seconds 
     pause:
       seconds: 10
     tags:
      - kafka_protocol_message_2_3
      - kafka_protocol_message_2_6

#
# Kafka rolling restart, use like:
# $ ansible-playbook playbook_kafka.yml --tags kafka_rolling_restart --limit red01,red02,red03 -e serial_number=1
#
   - name: Restart Kafka 
     service:
       name: kafka.service
       state: restarted
       enabled: yes
       daemon_reload: yes
     tags:
      - kafka_rolling_restart

   - name: Wait 10 seconds 
     pause:
       seconds: 10
     tags:
      - kafka_rolling_restart



#
# Prometheus exporter (required for start as is included in service script)
#

   - name: Creates /opt/prometheus directory
     file:
       path: /opt/prometheus
       state: directory
     tags:
      - jmx_prometheus_javaagent-0.3.1
      - jmx_prometheus_javaagent-0.16.1

   - name: Download jmx_prometheus_javaagent-0.3.1.jar
     get_url:
       url: https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.3.1/jmx_prometheus_javaagent-0.3.1.jar
       dest: /opt/prometheus/jmx_prometheus_javaagent-0.3.1.jar
       checksum: md5:4f08e57afb4088469904956237c0cf8e
     tags:
      - jmx_prometheus_javaagent-0.3.1

   - name: Download kafka-0-8-2.yml
     get_url:
       url: https://raw.githubusercontent.com/prometheus/jmx_exporter/master/example_configs/kafka-0-8-2.yml
       dest: /opt/prometheus/kafka-0-8-2.yml
       checksum: md5:8341aa61b494660132ab8a6c7312a780
     tags:
      - jmx_prometheus_javaagent-0.3.1

   - name: Download mx_prometheus_javaagent-0.16.1.jar
     get_url:
       url: https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.16.1/jmx_prometheus_javaagent-0.16.1.jar
       dest: /opt/prometheus/jmx_prometheus_javaagent-0.16.1.jar
       checksum: md5:2882dbb749e2bdfba6cc44f9f992ccd8
     tags:
      - jmx_prometheus_javaagent-0.16.1

   - name: Download kafka-2_0_0.yml
     get_url:
       url: https://raw.githubusercontent.com/prometheus/jmx_exporter/master/example_configs/kafka-2_0_0.yml
       dest: /opt/prometheus/kafka-2_0_0.yml
       #checksum: md5:3ac75e7b2dbf441945a4fc8bc06e9e39
     tags:
      - jmx_prometheus_javaagent-0.16.1


   - name: Download kafka_broker.yml
     get_url:
       url: https://raw.githubusercontent.com/confluentinc/jmx-monitoring-stacks/6.1.0-post/shared-assets/jmx-exporter/kafka_broker.yml
       dest: /opt/prometheus/kafka_broker.yml
       #checksum: md5:ffcdb7d5619a204a236353b5ecab9d83
     tags:
      - kafka_1.1.1
      - jmx_prometheus_javaagent-0.16.1


   - name: Jolokia - Creates /opt/jolokia directory
     file:
       path: /opt/jolokia
       state: directory
     tags:
      - jolokia

   - name: Jolokia - Download jolokia-jvm-1.6.0-agent.jar
     get_url:
       url: http://search.maven.org/remotecontent?filepath=org/jolokia/jolokia-jvm/1.6.0/jolokia-jvm-1.6.0-agent.jar
       dest: /opt/jolokia/jolokia-agent.jar
       checksum: md5:01df022b01a34c9b021231172adc776b
     tags:
      - jolokia



#
# Startup script as systemd service
#


   - name: Run Kafka as a service
     copy:
       dest: /etc/systemd/system/kafka.service
       backup: yes
       content: |
         [Unit]
         Requires=network.target remote-fs.target
         After=network.target remote-fs.target
         StartLimitIntervalSec=600
         StartLimitBurst=10

         [Service]
         Type=simple
         User=root
         Environment="JMX_PORT=9999"
         Environment="KAFKA_HEAP_OPTS=-Xmx300M -Xms256M"
         #Environment="KAFKA_OPTS=-javaagent:/opt/prometheus/jmx_prometheus_javaagent-0.3.1.jar=8080:/opt/prometheus/kafka-0-8-2.yml -javaagent:/opt/jolokia/jolokia-agent.jar=host=*"
         #Environment="KAFKA_OPTS=-javaagent:/opt/prometheus/jmx_prometheus_javaagent-0.16.1.jar=8080:/opt/prometheus/kafka-2_0_0.yml -javaagent:/opt/jolokia/jolokia-agent.jar=host=*"
         Environment="KAFKA_OPTS=-javaagent:/opt/prometheus/jmx_prometheus_javaagent-0.16.1.jar=8080:/opt/prometheus/kafka_broker.yml -javaagent:/opt/jolokia/jolokia-agent.jar=host=*"
         ExecStart=/bin/sh -c '/opt/kafka/bin/kafka-server-start.sh /etc/kafka/server.properties > /opt/kafka/logs/kafka_start.log 2>&1'
         ExecStop=/opt/kafka/bin/kafka-server-stop.sh
         Restart=on-failure
         RestartSec=60s

         [Install]
         WantedBy=multi-user.target
     register: kafka
     tags:
      - service

   - name: Start Kafka 
     service:
       name: kafka.service
       state: started
       enabled: yes
     tags:
      - service

   - name: Restart Kafka if some configuration has changed
     service:
       name: kafka.service
       state: restarted
       enabled: yes
       daemon_reload: yes
     when: kafka.changed
     tags:
      - service

#
# -----------
#







#
# --- zookeeper
# WIP

   - name: Creates /opt/zk-data directory
     file:
       path: /opt/zk-data
       state: directory
     tags:
      - zookeeper

   - name: Modify /opt/kafka/config/zookeeper.properties dataDir
     replace:
       path: /opt/kafka/config/zookeeper.properties
       regexp: '^dataDir=/tmp/zookeeper'
       replace: 'dataDir=/opt/zk-data'
     register: zookeeper
     tags:
      - zookeeper

   - name: Run Zookeeper from Kafka binaries as a service
     copy:
       dest: /etc/systemd/system/zookeeper.service
       backup: yes
       content: |
         [Unit]
         Requires=network.target remote-fs.target
         After=network.target remote-fs.target
         StartLimitIntervalSec=600
         StartLimitBurst=10

         [Service]
         Type=simple
         User=root
         ExecStart=/opt/kafka/bin/zookeeper-server-start.sh /opt/kafka/config/zookeeper.properties
         ExecStop=/opt/kafka/bin/zookeeper-server-stop.sh
         Restart=on-failure
         RestartSec=60s

         [Install]
         WantedBy=multi-user.target
     register: zookeeper
     tags:
      - zookeeper

   - name: Restart Zookeeper if some configuration has changed
     service:
       name: zookeeper.service
       state: restarted
       enabled: yes
       daemon_reload: yes
     when: zookeeper.changed
     tags:
      - zookeeper
#
# /zookeeper
#

   - name: Creates /opt/kafka-1.1.1-data directory
     file:
       path: /opt/kafka_2.12-1.1.1/logs
       state: directory
     tags:
      - kafka_1.1.1





#
# Upgrade
#
   - name: Upgrade to Kafka 2 - Modify server.properties add 
     blockinfile:
       path: /opt/kafka_2.12-1.1.1/config/server.properties
       backup: yes
       marker: "# {mark} ANSIBLE MANAGED UPGRADE 2 BLOCK"
       block: |
         inter.broker.protocol.version=1.1
         log.message.format.version=1.1
     register: kafka_config
     tags:
      - kafka_up_2a

   - name: Restart Kafka 1.1.1 if some configuration has changed
     service:
       name: kafka.service
       state: restarted
       enabled: yes
       daemon_reload: yes
     when: kafka_config.changed
     tags:
      - kafka_up_2a

   - name: Wait 10 seconds 
     pause:
       seconds: 10
     tags:
      - kafka_up_2a




# Kafka upgrade from 1.1.1 to 2.3.0
   - name: Copy /opt/kafka_2.12-1.1.1/config/server.properties to /opt/kafka_2.12-2.3.0/config/
     ansible.builtin.copy:
       remote_src: yes
       src: /opt/kafka_2.12-1.1.1/config/server.properties
       dest: /opt/kafka_2.12-2.3.0/config/server.properties
       backup: yes
     tags:
      - kafka_2.3.0_copy_from_1.1.1

   - name: Restart Kafka from new binaries
     service:
       name: kafka.service
       state: restarted
       enabled: yes
       daemon_reload: yes
     tags:
      - kafka_restart

   - name: Wait 10 seconds 
     pause:
       seconds: 10
     tags:
      - kafka_restart

   - name: Upgrade to Kafka 2 - Modify server.properties add 
     blockinfile:
       path: /opt/kafka_2.12-2.3.0/config/server.properties
       backup: yes
       marker: "# {mark} ANSIBLE MANAGED UPGRADE 2 BLOCK"
       block: |
         inter.broker.protocol.version=2.3
         log.message.format.version=1.1
     register: kafka_config
     tags:
      - kafka_inter_broker_2_3

   - name: Upgrade to Kafka 2 - Modify server.properties add 
     blockinfile:
       path: /opt/kafka_2.12-2.3.0/config/server.properties
       backup: yes
       marker: "# {mark} ANSIBLE MANAGED UPGRADE 2 BLOCK"
       block: |
         inter.broker.protocol.version=2.3
         log.message.format.version=2.3
     register: kafka_config
     tags:
      - kafka_log_message_2_3

#
# Mirror - maker
#
   - name: Checking loop
     debug:
       msg="Now working with {{ item }}"
     loop: "{{ mm_scripts }}"
     tags:
      - mm_scripts

   - name: Mirror Maker - check if configured script exists
     stat:
       path: "{{ item }}"
     loop: "{{ mm_scripts }}"
     register: stat_result
     tags:
      - mm_scripts

   - name: Mirror Maker - if file exists
     debug:
       #msg="Will work with {{ item.item }}"
       #msg="Will work with {{ item.item | basename }}"
       #msg="Will work with {{ item.item | dirname }}"
       msg="Will work with {{ item.item.split(".")[0] | basename }}"
     loop: "{{ stat_result.results }}"
     when: item.stat.exists
     tags:
      - mm_scripts

   - name: Mirror Maker - Create systemd script from template 
     template:
       src: ~/scripto/ansible/templates/systemd_mirror_maker_job.j2
       dest: /etc/systemd/system/{{ item.item.split(".")[0] | basename }}.service
       backup: yes
     loop: "{{ stat_result.results }}"
     when: item.stat.exists
     tags:
      - mm_scripts


   - name: Enable "{{ item.item.split(".")[0] | basename }}" service for automatic start
     service:
       name: "{{ item.item.split('.')[0] | basename }}"
       state: started
       enabled: yes
       daemon_reload: yes
     loop: "{{ stat_result.results }}"
     when: item.stat.exists
     tags:
      - mm_scripts


   - name: Creates /var/log/mirror_maker directory
     ansible.builtin.file:
       path: /var/log/mirror_maker
       state: directory
       owner: root
       group: root
       mode: '0755'
     tags:
      - mm_scripts


#
# Mirror maker monitoring
#
   - name: Checking loop
     debug:
       msg="Checking if the following processes are running {{ ps_check }}"
     tags:
      - mm_monitor

   - name: Look for the "foo" process
     shell: ps -ef |  grep "{{ ps_check }}" | grep -v grep
     register: process_list
     changed_when: false  
     failed_when: process_list.rc != 1 and process_list.rc != 0
     tags:
      - mm_monitor

   - name: (debug) What I found running 
     debug:
       msg="check {{ process_list }}"
     tags:
      - mm_monitor

   - name: Process is not running, doing something with it.
     shell: echo "ala ma kota" >> /tmp/ala_ma_kota
     when: "process_list.rc == 1"  
     tags:
      - mm_monitor

   - name: Sending an e-mail using Gmail SMTP servers
     mail:
       host: smtp.gmail.com
       port: 587
       username: "{{ vault_email_username }}"
       password: "{{ vault_email_password }}"
       to: remigiusz.boguszewicz@gmail.com
       subject: Ansible Report
       body: System [[ ansible_hostname ]] has been successfully provisioned.
     when: "process_list.rc == 1"  
     tags:
      - mm_monitor


#
# Kafka exporter 
#
   - name: Download kafka_exporter-1.3.1.linux-armv7.tar.gz
     get_url:
       url: https://github.com/danielqsj/kafka_exporter/releases/download/v1.3.1/kafka_exporter-1.3.1.linux-armv7.tar.gz
       dest: /opt/kafka_exporter-1.3.1.linux-armv7.tar.gz
       checksum: md5:1aa0fbc9bdf5507beeca7009e88b41a8
     tags:
      - danielqsj_kafka_exporter_1.3.1

   - name: Extract kafka_exporter-1.3.1.linux-armv7.tar.gz into /opt
     unarchive:
       src: /opt/kafka_exporter-1.3.1.linux-armv7.tar.gz
       dest: /opt
       remote_src: yes
       creates: /opt/kafka_exporter-1.3.1.linux-armv7
     tags:
      - danielqsj_kafka_exporter_1.3.1

   - name: Run kafka_exporter-1.3.1.linux-armv7 as a service
     copy:
       dest: /etc/systemd/system/kafka_exporter_131.service
       backup: yes
       content: |
         [Unit]
         Requires=network.target remote-fs.target
         After=network.target remote-fs.target
         StartLimitIntervalSec=600
         StartLimitBurst=10

         [Service]
         Type=simple
         User=root
         ExecStart=/opt/kafka_exporter-1.3.1.linux-armv7/kafka_exporter --kafka.server={{ ansible_ssh_host }}:9092
         Restart=on-failure
         RestartSec=60s

         [Install]
         WantedBy=multi-user.target
     register: kafka_exporter_131
     tags:
      - danielqsj_kafka_exporter_1.3.1

   - name: Start kafka_exporter_131
     service:
       name: kafka_exporter_131.service
       state: started
       enabled: yes
       daemon_reload: yes
     when: kafka_exporter_131.changed
     tags:
      - danielqsj_kafka_exporter_1.3.1

#
# Install Kafka Manager - CMAK: (Yahoo)
#

   - name: Download https://github.com/yahoo/CMAK/releases/download/3.0.0.5/cmak-3.0.0.5.zip
     get_url:
       url: https://github.com/yahoo/CMAK/releases/download/3.0.0.5/cmak-3.0.0.5.zip
       dest: /opt/cmak-3.0.0.5.zip
       checksum: md5:10f5307e780ae88cca888e39b763b42e
     tags:
      - kafka_cmak

   - name: Extract cmak-3.0.0.5.zip into /opt
     unarchive:
       src: /opt/cmak-3.0.0.5.zip
       dest: /opt
       remote_src: yes
       creates: /opt/cmak-3.0.0.5
     tags:
      - kafka_cmak

   - name: Install required packages
     apt:
       name: default-jdk
       state: present
     tags:
      - kafka_cmak

   - name: Modify application.conf and set local ZK
     replace:
       path: /opt/cmak-3.0.0.5/conf/application.conf
       regexp: 'kafka-manager-zookeeper'
       replace: '{{ ansible_ssh_host }}'
       backup: yes
     tags:
      - kafka_cmak

   - name: Run CMAK as a service
     copy:
       dest: /etc/systemd/system/kafka_cmak.service
       backup: yes
       content: |
         [Unit]
         Requires=network.target remote-fs.target
         After=network.target remote-fs.target
         StartLimitIntervalSec=600
         StartLimitBurst=10

         [Service]
         Type=simple
         User=root
         Environment="JAVA_HOME=/usr/lib/jvm/java-11-openjdk-armhf"
         ExecStart=/opt/cmak-3.0.0.5/bin/cmak -Dhttp.port=9100
         Restart=on-failure
         RestartSec=60s

         [Install]
         WantedBy=multi-user.target
     register: kafka_cmak
     tags:
      - kafka_cmak

   - name: Start kafka_cmak
     service:
       name: kafka_cmak.service
       state: restarted
       enabled: yes
       daemon_reload: yes
     when: kafka_cmak.changed
     tags:
      - kafka_cmak

   - name: Installing cronjob ro remove /opt/cmak-3.0.0.5/RUNNING_PID on startup as it usually stays there and prevents startup
     ansible.builtin.cron:
       name: "remove /opt/cmak-3.0.0.5/RUNNING_PID on startup as it usually stays there and prevents CMAK startup"
       special_time: reboot
       job: "rm -f /opt/cmak-3.0.0.5/RUNNING_PID"
     tags:
      - kafka_cmak

#
# Schema Registry
#
   - name: Run schema registry as a service
     copy:
       dest: /etc/systemd/system/schema_registry.service
       backup: yes
       content: |
         [Unit]
         Requires=network.target remote-fs.target
         After=network.target remote-fs.target
         StartLimitIntervalSec=600
         StartLimitBurst=10

         [Service]
         Type=simple
         User=root
         WorkingDirectory=/opt/confluent/confluent-5.3.8
         Environment="JAVA_HOME=/usr/lib/jvm/java-11-openjdk-armhf"
         ExecStart=/opt/confluent/confluent-5.3.8/bin/schema-registry-start /opt/confluent/confluent-5.3.8/etc/schema-registry/schema-registry.properties
         Restart=on-failure
         RestartSec=60s

         [Install]
         WantedBy=multi-user.target
     register: schema_registry
     tags:
      - schema_registry

   - name: Start schema_registry
     service:
       name: schema_registry.service
       state: restarted
       enabled: yes
       daemon_reload: yes
     when: schema_registry.changed
     tags:
      - schema_registry

#
# Run tcpdump when there are URPs visible
#

   - name: Creates /home/tcpdump directory
     ansible.builtin.file:
       path: /home/tcpdump
       state: directory
       mode: '0755'
     tags:
      - tcpdump_when_urps

   - name: Copy run_tcpdump.sh to /home/tcpdump
     ansible.builtin.copy:
       src: ~/scripto/ansible/files/run_tcpdump.sh
       dest: /home/tcpdump/run_tcpdump.sh
       backup: no
     tags:
      - tcpdump_when_urps

   - name: Make /home/tcpdump/run_tcpdump.sh 755
     ansible.builtin.file:
       path: /home/tcpdump/run_tcpdump.sh
       state: file
       owner: root
       group: root
       mode: '0755'
     tags:
      - tcpdump_when_urps


   - name: Run schema registry as a service
     copy:
       dest: /etc/systemd/system/tcpdump_when_urps.service
       backup: no
       content: |
         [Unit]
         Requires=network.target remote-fs.target
         After=network.target remote-fs.target
         StartLimitIntervalSec=600
         StartLimitBurst=10

         [Service]
         Type=simple
         User=root
         WorkingDirectory=/home/tcpdump
         ExecStart=/bin/sh -c '/home/tcpdump/run_tcpdump.sh >> /var/log/tcpdump_when_urps.log 2>&1'
         Restart=on-failure
         RestartSec=60s

         [Install]
         WantedBy=multi-user.target
     register: tcpdump_when_urps
     tags:
      - tcpdump_when_urps

   - name: Start tcpdump_when_urps
     service:
       name: tcpdump_when_urps.service
       state: restarted
       enabled: yes
       daemon_reload: yes
     when: tcpdump_when_urps.changed
     tags:
      - tcpdump_when_urps

   - name: Stop and disable tcpdump_when_urps
     service:
       name: tcpdump_when_urps.service
       state: stopped
       enabled: no
       daemon_reload: yes
     tags:
      - tcpdump_when_urps_stop



#
# debug
#
   - name: Display all variables/facts known for a host
     debug:
       var: hostvars[inventory_hostname]
     tags:
      - debug_info
      - never
